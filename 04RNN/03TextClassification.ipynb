{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ-IR8704qqO"
   },
   "source": [
    "# Text classification with the torchtext library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhQpG--y5vB3"
   },
   "source": [
    "### Access to the raw dataset iterator\n",
    "\n",
    "AG_NEWS dataset iterators는 원시 데이터를 레이블과 텍스트의 튜플로 생성한다.\n",
    "\n",
    "AG_NEWS 데이터셋에는 4 종류의 레이블이 달려 있다.\n",
    "\n",
    "1 : World   \n",
    "2 : Sports   \n",
    "3 : Business   \n",
    "4 : Sci/Tec  \n",
    "\n",
    "각 split의 데이터 건수는 \n",
    "train: 120000, test: 7600 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lrQwlb54Ov4",
    "outputId": "f002bab7-d7b9-4bb7-aafe-a511bda382aa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "train_iter = AG_NEWS(root='data', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBHq_KX1_V19",
    "outputId": "ee42f81e-2674-4cde-e5c2-7d691dc94147"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter.num_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EiJhXsFD49tU",
    "outputId": "627fb07b-3f9f-4d31-8f52-d6e9d3608fe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAd4tkb95MGc"
   },
   "source": [
    "### Prepare data processing pipelines\n",
    "\n",
    "\n",
    "다음은 tokenizer 및 vocabulary를 사용한 일반적인 자연어 데이터 처리의 예입니다.\n",
    "첫 번째 단계는 원시 학습 데이터 세트로 vocabulary를 구축하는 것이다. `torchtext.vocab.vocab` 클래스의 옵션을 설정하여 사용자 정의의 vocabulary를 생성할 수 있다.\n",
    "\n",
    "`build_vocab_from_iterator `를 사용하여 vocabulary를 생성한다.\n",
    "\n",
    "참고) [torchtext.vocab.build_vocab_from_iterator](https://pytorch.org/text/stable/vocab.html#build-vocab-from-iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = AG_NEWS(split='train')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# unk는 단어 집합에 없는 단어를 표현할 때 사용\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6Xnl_Kp6Ef4"
   },
   "source": [
    "token 리스트의 값을 정수로 변환할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-pegJGU5-TT",
    "outputId": "f6d0eac9-d050-4b09-fabc-90fd0c1fe6db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[475, 21, 30, 5297]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab[token] for token in ['here', 'is', 'an', 'example']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGubpRsg6Sti"
   },
   "source": [
    "text_pipeline은 vocab에 정의된 조회 테이블을 기반으로 텍스트 문자열을 정수 목록으로 변환한다. label_pipeline은 레이블을 정수로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "_hxcIs5N6Oxi"
   },
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O4Je-KedAFRq",
    "outputId": "40444b07-bc07-4c38-f4fc-590a23811778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[475, 21, 2, 30, 5297]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('here is the an example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFSzK8uuAFg5",
    "outputId": "60a3afca-f266-4537-deac-9a2a763b63ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline('10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "713547MFAUDJ"
   },
   "source": [
    "### Generate data batch and iterator\n",
    "\n",
    "`torch.utils.data.DataLoader `을 사용하여 원시 데이터를 데이터셋으로 생성할 수 있다.\n",
    "\n",
    "텍스트 원소의 길이가 다를 수 있으므로, 데이터 배치와 오프셋을 생성하기 위한 사용자 함수 collate_batch()를 사용한다. 이 함수는 `torch.utils.data.DataLoader `의 `collate_fn` 인자로 넘겨준다.\n",
    "\n",
    "`collate_fn` 의 입력은 그 크기가 batch_size인 텐서들의 리스트이며, `collate_fn` 은 이들을 미니배치로 묶는 역할을 한다. \n",
    "\n",
    "함수 collate_batch()는 앞서 선언한 `text_pipeline`과 `label_pipeline`을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ZIVcZw3hAMb3"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "max_len = 50\n",
    "\n",
    "def collate_batch(batch, max_len=max_len):\n",
    "    label_list, text_list = [], []\n",
    "\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        text_holder = torch.ones(max_len, dtype=torch.int32) # fixed size tensor of max_len\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        pos = min(max_len, len(processed_text))\n",
    "        text_holder[-pos:] = processed_text[-pos:]\n",
    "        text_list.append(text_holder.unsqueeze(dim=0))\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device)    \n",
    "\n",
    "train_iter = AG_NEWS(root='data', split='train')\n",
    "\n",
    "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "terhyPk1Jpro"
   },
   "source": [
    "### Define the model\n",
    "\n",
    "모형은 nn.Embedding과 뉴스 분류를 위한 linear layer로 구성된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Cj00QpePKmgN"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.LSTM = nn.LSTM(embed_dim, hidden_size=64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, num_class)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, _ = self.LSTM(embedded)\n",
    "        last_output = output[:,-1,:]\n",
    "        return self.fc(last_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGs8u3PHPVDM"
   },
   "source": [
    "### Initiate instance\n",
    "\n",
    "임베딩 차원이 64 인 모델을 생성한다. vocaburary 크기는 vocaburary 인스턴스의 길이와 같다. 클래스 수는 레이블 수와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "At8Xsk8JPqCW"
   },
   "outputs": [],
   "source": [
    "num_class = 4\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "max_len = 50\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_Zsr5DkQIm6"
   },
   "source": [
    "### Define functions to train the model and evaluate results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "DIMvpg79QKni"
   },
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predited_label = model(text)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WczsJFz9WCbX"
   },
   "source": [
    "### Split the dataset and run the model\n",
    "\n",
    "원래 AG_NEWS에는 valid 데이터 세트가 없으므로 훈련 데이터 세트를 0.95 (train) 및 0.05 (valid)의 분할 비율로 train / valid 세트로 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "i7JGH2OiP9ht"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 1 # epoch\n",
    "LR = 0.001 # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvesogBtXFPh",
    "outputId": "5e3d8e26-1018-4a71-82c9-8001cd568d4c"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "total_accu = None\n",
    "\n",
    "train_iter, test_iter = AG_NEWS(root='data')\n",
    "train_dataset = list(train_iter)\n",
    "test_dataset = list(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ah706EuHiabU",
    "outputId": "a4cd4901-ea59-4cfe-ea48-f2eda73bcf99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 0, 3, 2, 2, 1, 1, 3, 1, 0, 0, 2, 0, 1, 3, 0, 0, 1, 1, 0, 1, 1, 3,\n",
      "        0, 2, 1, 3, 1, 2, 0, 3, 3, 3, 0, 0, 2, 2, 0, 3, 0, 1, 1, 0, 2, 3, 0, 1,\n",
      "        0, 3, 3, 0, 2, 3, 2, 3, 0, 2, 0, 2, 2, 2, 2, 2]) \n",
      " tensor([[   97,   236,     3,  ...,   475,    57,     1],\n",
      "        [  800,     4, 38659,  ...,   163,    41,  1532],\n",
      "        [    1,     1,     1,  ...,    10,    57,     1],\n",
      "        ...,\n",
      "        [   34,  1390,   124,  ...,  1340,   119,     1],\n",
      "        [  148,    29,    50,  ...,   583,   611,     1],\n",
      "        [    1,  8385,   572,  ...,    18,   919,     1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a,b = next(iter(train_dataloader))\n",
    "print(a,'\\n', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eglu1rENetXW",
    "outputId": "61ee4b0d-6a80-4da5-e35e-7096a22246c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch   1 : valid accuracy    0.866 \n"
     ]
    }
   ],
   "source": [
    "print('Training the model...')\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    \n",
    "    print('Epoch {:3d} : '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           accu_val))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2QkUhy1qU21"
   },
   "source": [
    "### Evaluate the model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bv8wG2loqS7d",
    "outputId": "2c05fc84-9d2e-4915-94eb-b8f0914461b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.863\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYkw2fSUqcWt"
   },
   "source": [
    "### Test on a random news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x663YQfCqhOe",
    "outputId": "50a89833-183f-4786-f7bf-8a96eb7dcfd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Sci/Tec news\n"
     ]
    }
   ],
   "source": [
    "ag_news_label = {1: \"World\",\n",
    "                 2: \"Sports\",\n",
    "                 3: \"Business\",\n",
    "                 4: \"Sci/Tec\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text_holder = torch.ones(max_len, dtype=torch.int32) \n",
    "        processed_text = torch.tensor(text_pipeline(text))\n",
    "        pos = min(max_len, len(processed_text))\n",
    "        text_holder[-pos:] = processed_text[-pos:]\n",
    "        output = model(text_holder.unsqueeze(dim=0))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "ex_text_str = \"A pioneer in machine learning has argued that the technology is best placed to \\\n",
    "augment human intelligence and bemoaned ‘confusion’ over the meaning of \\\n",
    "artificial intelligence (AI). Michael I. Jordan, a professor in the department \\\n",
    "of electrical engineering and computer science, and department of statistics, \\\n",
    "at the University of California, Berkeley, told the IEEE that while \\\n",
    "science-fiction discussions around AI were ‘fun’, they were also a ‘distraction.’\"\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, text_pipeline)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TextClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
